{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ztPzCU-QOssXMBSwlYFbPVtOZhe0pM0m","timestamp":1750997474431}],"authorship_tag":"ABX9TyOboAdokbpYCkq7fz+09tmq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"bY28mMPJhdSJ","executionInfo":{"status":"ok","timestamp":1751853166204,"user_tz":180,"elapsed":14778,"user":{"displayName":"Glauco Geremias","userId":"11920507635531894731"}}},"outputs":[],"source":["!pip install pandas scikit-learn transformers torch tensorflow -q"]},{"cell_type":"markdown","source":["Carrega as bibliotecas para a execução dos modelos."],"metadata":{"id":"AzcX3dY7CYBO"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import pickle\n","import torch\n","import nltk\n","import os\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.linear_model import LogisticRegression\n","from transformers import AutoTokenizer, AutoModel\n","from nltk.corpus import stopwords\n","import matplotlib.pyplot as plt\n","from google.colab import files"],"metadata":{"id":"kaDK2E3W703y","executionInfo":{"status":"ok","timestamp":1751853192118,"user_tz":180,"elapsed":25918,"user":{"displayName":"Glauco Geremias","userId":"11920507635531894731"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["Carrega o arquivo que será utilizado para o treinamento."],"metadata":{"id":"i-CZzz0180SJ"}},{"cell_type":"code","source":["filename = 'transacoes_completas.csv'\n","\n","if not os.path.exists(filename):\n","    print(f\"File '{filename}' not found. Please upload the file.\")\n","    uploaded = files.upload()\n","    if uploaded:\n","        filename = list(uploaded.keys())[0]\n","        print(f\"File '{filename}' uploaded successfully.\")\n","    else:\n","        print(\"No file was uploaded.\")\n","else:\n","    print(f\"File '{filename}' is already loaded.\")"],"metadata":{"id":"WzBwgN9_8y9P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751853192150,"user_tz":180,"elapsed":29,"user":{"displayName":"Glauco Geremias","userId":"11920507635531894731"}},"outputId":"b5f6a090-1f36-4fb4-9b4c-41528c5c962a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["File 'transacoes_completas.csv' is already loaded.\n"]}]},{"cell_type":"markdown","source":["Carregar dataset do arquivo uploaded usando on_bad_lines='skip' para pular linhas com problemas de parsing, após carregado exibe as dez primeiras linhas como amostra."],"metadata":{"id":"8OAlKqem9UrE"}},{"cell_type":"code","source":["dataset = pd.read_csv(filename, delimiter=';', on_bad_lines='skip')\n","print(dataset.head())"],"metadata":{"id":"cLTaVSiP9MFN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751853192191,"user_tz":180,"elapsed":38,"user":{"displayName":"Glauco Geremias","userId":"11920507635531894731"}},"outputId":"de233623-8298-4472-f1db-79b5b8613f42"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["         data                 descricao categoria   Valor\n","0  2022-08-21  Farmácia Drogaria Araujo       SAU  113.98\n","1  2021-08-17           deb autor abril       ASS  156.93\n","2  2024-12-29  Assinatura Deezer Mensal       ASS  103.29\n","3  2023-09-04    lanchonete e churrasca       BAR  877.90\n","4  2021-04-27         rshop-sacolao che       MER  485.60\n"]}]},{"cell_type":"markdown","source":["***Pré processamento do texto:***\n","\n","- Baixa a lista de palavras irrelevantes (stopwords) da linguagem natural — como “de”, “o”, “e”, “para”, etc. — que geralmente não carregam muito significado em tarefas de processamento de texto.\n","\n","- Cria um conjunto com todas as stopwords em português, para facilitar a checagem rápida (sets são mais eficientes que listas para esse tipo de operação)."],"metadata":{"id":"Fb89soWwG8n8"}},{"cell_type":"code","source":["nltk_data_dir = os.path.join(os.path.expanduser(\"~\"), \"nltk_data\", \"corpora\", \"stopwords\")\n","\n","# Verifica se o diretório de stopwords existe\n","if not os.path.exists(nltk_data_dir):\n","    nltk.download(\"stopwords\", quiet=True)\n","\n","stop_words = set(stopwords.words('portuguese'))"],"metadata":{"id":"kwdE7iAzG0IX","executionInfo":{"status":"ok","timestamp":1751853192199,"user_tz":180,"elapsed":2,"user":{"displayName":"Glauco Geremias","userId":"11920507635531894731"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"b98d7e00","executionInfo":{"status":"ok","timestamp":1751853192216,"user_tz":180,"elapsed":4,"user":{"displayName":"Glauco Geremias","userId":"11920507635531894731"}}},"source":["# Defina seu dicionário customizado de palavras a serem removidas\n","custom_stop_words = set([\n","    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n","    'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U',\n","    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n","    '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~'\n","])"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["Para cada linha da coluna \"descricao\":\n","* Divide o texto em palavras (x.split()).\n","* Filtra aquelas que não estão nas stopwords (if word.lower() not in stop_words).\n","* Junta as palavras de volta em um único texto com \" \".join(...).\n","* Salva o resultado na nova coluna chamada descricao_processed.\n","\n","Exemplo prático:\n","Se descricao = \"Conta de luz de fevereiro\", após esse processamento, o texto vira algo como: \"Conta luz fevereiro\"\n","(Remove \"de\", que é uma stopword.)"],"metadata":{"id":"GZwTXuRDJbDD"}},{"cell_type":"code","source":["def preprocess_text(text):\n","    if isinstance(text, str):\n","        text = text.lower()\n","        # Combina o NLTK stopwords e a lista customizada\n","        all_stop_words = stop_words.union(custom_stop_words)\n","        tokens = [word for word in text.split() if word not in all_stop_words and len(word) > 2]\n","        return \" \".join(tokens)\n","    else:\n","        return \"\"\n","\n","dataset['descricao_processed'] = dataset['descricao'].apply(preprocess_text)\n","print(dataset[['descricao', 'descricao_processed']].head())"],"metadata":{"id":"gZ_xAzHoJRlj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751853192251,"user_tz":180,"elapsed":31,"user":{"displayName":"Glauco Geremias","userId":"11920507635531894731"}},"outputId":"da6f48fa-d2f6-432f-c971-56ebcb682d7c"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["                  descricao       descricao_processed\n","0  Farmácia Drogaria Araujo  farmácia drogaria araujo\n","1           deb autor abril           deb autor abril\n","2  Assinatura Deezer Mensal  assinatura deezer mensal\n","3    lanchonete e churrasca      lanchonete churrasca\n","4         rshop-sacolao che         rshop-sacolao che\n"]}]},{"cell_type":"markdown","source":["***Tokenização:***\n","\n","Transforma os textos em representações numéricas vetoriais usando a técnica TF-IDF (Term Frequency–Inverse Document Frequency).\n","\n","Inicializa o vetor com:\n","- max_features=1000: limita o vocabulário a 1000 palavras mais relevantes (com maior valor TF-IDF).\n","- Outros parâmetros possíveis: min_df, max_df, ngram_range, etc.\n","\n","Transforma a coluna descricao_processed (que já teve stopwords removidas, por exemplo) em uma matriz esparsa de TF-IDF.\n","- O resultado é uma matriz com dimensões = (número de documentos, número de palavras selecionadas).\n","Exibe o tamanho da matriz gerada (por exemplo, 1000 documentos x 1000 palavras).\n","\n","Mostra as palavras selecionadas como colunas da matriz — ou seja, o vocabulário final."],"metadata":{"id":"y2BBBKzOK9Qi"}},{"cell_type":"code","source":["tfidf_vectorizer = TfidfVectorizer(min_df=10, max_df=0.80, max_features=1000, strip_accents='unicode')\n","tfidf_matrix = tfidf_vectorizer.fit_transform(dataset['descricao_processed'])\n","\n","print(\"Forma da matriz TF-IDF:\", tfidf_matrix.shape)\n","print(\"Features extraídas:\", tfidf_vectorizer.get_feature_names_out())"],"metadata":{"id":"TXg3F_J4K8aM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751853192332,"user_tz":180,"elapsed":79,"user":{"displayName":"Glauco Geremias","userId":"11920507635531894731"}},"outputId":"7ffa2562-ea32-49c7-f14c-f46a80fe428a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Forma da matriz TF-IDF: (2000, 86)\n","Features extraídas: ['agro' 'agua' 'amazon' 'american' 'americana' 'assinatura' 'atac'\n"," 'atacadao' 'aut' 'auto' 'autor' 'bar' 'bki' 'cartao' 'casa' 'central'\n"," 'cobasi' 'com' 'comercio' 'compra' 'consulta' 'conta' 'corrente' 'cpfl'\n"," 'credito' 'ct' 'cxe' 'dae' 'deb' 'debito' 'doc' 'drogaria' 'emporio'\n"," 'estacioname' 'estacionamento' 'farma' 'farmacia' 'fatura' 'feira'\n"," 'hotel' 'ifd' 'ifood' 'int' 'ipva' 'itau' 'juros' 'lanches' 'loja'\n"," 'lojas' 'mensal' 'mercado' 'mercadolivre' 'multa' 'netflix' 'padaria'\n"," 'pag' 'pagamento' 'parar' 'paulista' 'pay' 'pending' 'pet' 'pizza'\n"," 'pizzaria' 'posto' 'premium' 'prime' 'restaurante' 'rotativo' 'rshop'\n"," 'sabesp' 'sao' 'saude' 'seguro' 'shop' 'shopping' 'sisdeb' 'sp' 'super'\n"," 'supermercado' 'tar' 'ted' 'trip' 'uber' 'vida' 'visa']\n"]}]},{"cell_type":"markdown","source":["Divide o dataset em dados de treino e teste:\n","- X: são os textos (descrições das contas).\n","- y: são as classes/etiquetas (tipo da conta).\n","- test_size=0.2: 20% dos dados serão usados para teste.\n","- random_state: garante reprodutibilidade.\n"],"metadata":{"id":"_eneupe1CC2d"}},{"cell_type":"code","source":["y = dataset['categoria']\n","X = tfidf_matrix\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","print(\"Forma do conjunto de treino (features):\", X_train.shape)\n","print(\"Forma do conjunto de teste (features):\", X_test.shape)\n","print(\"Forma do conjunto de treino (target):\", y_train.shape)\n","print(\"Forma do conjunto de teste (target):\", y_test.shape)"],"metadata":{"id":"xULd9W10CBvX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751853192333,"user_tz":180,"elapsed":12,"user":{"displayName":"Glauco Geremias","userId":"11920507635531894731"}},"outputId":"ebb8d17f-bd19-400f-d8d1-bc999a975e34"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Forma do conjunto de treino (features): (1600, 86)\n","Forma do conjunto de teste (features): (400, 86)\n","Forma do conjunto de treino (target): (1600,)\n","Forma do conjunto de teste (target): (400,)\n"]}]},{"cell_type":"markdown","source":["#***Modelo de Regressão Logística:***\n","- Cria um modelo de regressão logística com até 1000 iterações permitidas no processo de ajuste.\n"],"metadata":{"id":"vOIHTxgZoSqz"}},{"cell_type":"code","source":["model_lr = LogisticRegression(max_iter=1000, solver='saga', C=1.0, random_state=42)\n","model_lr.fit(X_train, y_train)\n","y_pred_lr = model_lr.predict(X_test)\n","\n","print(\"\\nRelatório de Classificação (Regressão Logística):\")\n","print(classification_report(y_test, y_pred_lr))\n","print(\"\\nAcurácia do modelo (Regressão Logística):\", accuracy_score(y_test, y_pred_lr))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LwLBlyhBOVgk","executionInfo":{"status":"ok","timestamp":1751853192505,"user_tz":180,"elapsed":176,"user":{"displayName":"Glauco Geremias","userId":"11920507635531894731"}},"outputId":"f33dc5c9-6ebd-47ad-efa5-eb6b6e1dcafc"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Relatório de Classificação (Regressão Logística):\n","              precision    recall  f1-score   support\n","\n","         ABS       1.00      0.83      0.91        36\n","         AGU       1.00      0.94      0.97        16\n","         APL       1.00      0.20      0.33         5\n","         ASS       0.72      0.78      0.75        23\n","         BAR       0.38      0.67      0.48        57\n","         CAS       0.00      0.00      0.00         8\n","         CRD       0.75      0.75      0.75         4\n","         EDU       0.00      0.00      0.00         4\n","         IMP       1.00      0.29      0.44         7\n","         JUR       1.00      1.00      1.00         6\n","         LAZ       1.00      0.38      0.55         8\n","         LOJ       0.37      0.49      0.42        77\n","         MAN       0.00      0.00      0.00         5\n","         MER       0.73      0.61      0.67        59\n","         PED       1.00      0.88      0.93         8\n","         PET       0.71      0.83      0.77         6\n","         SAL       0.00      0.00      0.00         6\n","         SAU       1.00      0.56      0.72        34\n","         SEG       1.00      0.71      0.83         7\n","         TAR       1.00      0.73      0.84        11\n","         TRP       0.92      0.92      0.92        13\n","\n","    accuracy                           0.61       400\n","   macro avg       0.69      0.55      0.59       400\n","weighted avg       0.67      0.61      0.62       400\n","\n","\n","Acurácia do modelo (Regressão Logística): 0.615\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"]}]},{"cell_type":"code","source":["import pickle\n","import os\n","\n","if not os.path.exists('models'):\n","    os.makedirs('models')\n","\n","with open('models/logistic_regression_model.pkl', 'wb') as f:\n","    pickle.dump(model_lr, f)\n","\n","with open('models/logistic_regression_vectorizer.pkl', 'wb') as f:\n","    pickle.dump(tfidf_vectorizer, f)"],"metadata":{"id":"CVtl_Ii3u7G0","executionInfo":{"status":"ok","timestamp":1751853192508,"user_tz":180,"elapsed":2,"user":{"displayName":"Glauco Geremias","userId":"11920507635531894731"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["#***Modelo RamdomForest:***\n","\n","Cria um pipeline com apenas uma etapa: o classificador Random Forest.\n","- n_estimators=100: o modelo vai construir 100 árvores para tomar decisões.\n","- random_state = 42: garante reprodutibilidade.\n","\n","Obs: O pipeline não inclui o TF-IDF, pois os dados (X_train) já estão vetorizados.\n","\n","- O modelo é treinado com os vetores de treino (X_train) e os rótulos (y_train).\n","- Depois, faz predições sobre os dados de teste (X_test), gerando y_pred_rf."],"metadata":{"id":"7fsYFhRv-JCa"}},{"cell_type":"code","source":["y = dataset['categoria']\n","X = tfidf_matrix\n","X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","pipeline_rf = Pipeline([\n","    (\"clf\", RandomForestClassifier(n_estimators=100, random_state=42))\n","])\n","\n","pipeline_rf.fit(X_train_rf, y_train_rf)\n","y_pred_rf = pipeline_rf.predict(X_test_rf)\n","\n","print(\"TF-IDF + Random Forest\")\n","print(classification_report(y_test, y_pred_rf))\n","print(\"\\nAcurácia do modelo (RamdomForest):\", accuracy_score(y_test_rf, y_pred_lr))"],"metadata":{"id":"2NjRvYDfhszt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751853193073,"user_tz":180,"elapsed":560,"user":{"displayName":"Glauco Geremias","userId":"11920507635531894731"}},"outputId":"f933c514-8af5-464a-f13a-32aaebcad500"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["TF-IDF + Random Forest\n","              precision    recall  f1-score   support\n","\n","         ABS       1.00      0.89      0.94        36\n","         AGU       0.94      0.94      0.94        16\n","         APL       1.00      0.20      0.33         5\n","         ASS       0.82      0.78      0.80        23\n","         BAR       0.83      0.33      0.47        57\n","         CAS       0.00      0.00      0.00         8\n","         CRD       1.00      0.75      0.86         4\n","         EDU       0.00      0.00      0.00         4\n","         IMP       1.00      0.29      0.44         7\n","         JUR       1.00      1.00      1.00         6\n","         LAZ       1.00      0.38      0.55         8\n","         LOJ       0.39      0.92      0.55        77\n","         MAN       0.00      0.00      0.00         5\n","         MER       0.71      0.58      0.64        59\n","         PED       1.00      0.88      0.93         8\n","         PET       0.62      0.83      0.71         6\n","         SAL       0.33      0.17      0.22         6\n","         SAU       1.00      0.53      0.69        34\n","         SEG       1.00      0.71      0.83         7\n","         TAR       1.00      0.82      0.90        11\n","         TRP       1.00      0.92      0.96        13\n","\n","    accuracy                           0.65       400\n","   macro avg       0.74      0.57      0.61       400\n","weighted avg       0.74      0.65      0.64       400\n","\n","\n","Acurácia do modelo (RamdomForest): 0.615\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"]}]},{"cell_type":"code","source":["import os\n","import pickle\n","\n","if not os.path.exists('models'):\n","    os.makedirs('models')\n","\n","with open('models/random_forest_model.pkl', 'wb') as f:\n","    pickle.dump(pipeline_rf, f)\n","\n","with open('models/random_forest_vectorizer.pkl', 'wb') as f:\n","    pickle.dump(tfidf_vectorizer, f)"],"metadata":{"id":"WTqYxfgbuF7I","executionInfo":{"status":"ok","timestamp":1751853193098,"user_tz":180,"elapsed":28,"user":{"displayName":"Glauco Geremias","userId":"11920507635531894731"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["#***Método Naive Bayes:***\n","\n","Implementa uma classificação de texto usando o método Bag-of-Words (BoW) com o classificador Naive Bayes (MultinomialNB).\n","\n","cria o pipeline com duas etapas:\n","- CountVectorizer() -\n","Transforma os textos em vetores de contagem (BoW), ou seja, cada texto vira uma matriz onde cada elemento representa quantas vezes uma palavra aparece.\n","- MultinomialNB() -\n","Um classificador baseado em probabilidades para dados de contagem como o BoW.\n","\n","Treina o modelo com os dados de treino. Ele aprende quais palavras são mais associadas a quais categorias.\n"],"metadata":{"id":"yMwt0QZqAGID"}},{"cell_type":"code","source":["X = dataset['descricao']\n","y = dataset['categoria']\n","X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","pipeline_bow_nb = Pipeline([\n","    (\"bow\", CountVectorizer()),\n","    (\"clf\", MultinomialNB())\n","])\n","\n","pipeline_bow_nb.fit(X_train_bow, y_train_bow)\n","y_pred_nb = pipeline_bow_nb.predict(X_test_bow)\n","\n","print(\"Bag-of-Words + Naive Bayes\")\n","print(classification_report(y_test_bow, y_pred_nb))\n","print(\"\\nAcurácia do modelo (Naive Bayes):\", accuracy_score(y_test_bow, y_pred_nb))"],"metadata":{"id":"ssNQqUPQhuU1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751853193186,"user_tz":180,"elapsed":89,"user":{"displayName":"Glauco Geremias","userId":"11920507635531894731"}},"outputId":"33ababde-923e-4663-d5c6-195bf065a08e"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Bag-of-Words + Naive Bayes\n","              precision    recall  f1-score   support\n","\n","         ABS       1.00      0.94      0.97        36\n","         AGU       0.80      1.00      0.89        16\n","         APL       1.00      0.60      0.75         5\n","         ASS       0.73      0.96      0.83        23\n","         BAR       0.71      0.72      0.71        57\n","         CAS       1.00      0.38      0.55         8\n","         CRD       1.00      1.00      1.00         4\n","         EDU       1.00      0.25      0.40         4\n","         IMP       1.00      0.57      0.73         7\n","         JUR       1.00      0.83      0.91         6\n","         LAZ       1.00      1.00      1.00         8\n","         LOJ       0.63      0.83      0.72        77\n","         MAN       0.00      0.00      0.00         5\n","         MER       0.84      0.81      0.83        59\n","         PED       1.00      0.75      0.86         8\n","         PET       1.00      0.50      0.67         6\n","         SAL       1.00      0.17      0.29         6\n","         SAU       0.97      0.91      0.94        34\n","         SEG       1.00      1.00      1.00         7\n","         TAR       1.00      1.00      1.00        11\n","         TRP       1.00      0.92      0.96        13\n","\n","    accuracy                           0.81       400\n","   macro avg       0.89      0.72      0.76       400\n","weighted avg       0.83      0.81      0.80       400\n","\n","\n","Acurácia do modelo (Naive Bayes): 0.81\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"]}]},{"cell_type":"code","source":["import pickle\n","import os\n","\n","if not os.path.exists('models'):\n","    os.makedirs('models')\n","\n","with open('models/naive_bayes_model.pkl', 'wb') as f:\n","    pickle.dump(pipeline_bow_nb, f)\n","\n","with open('models/naive_bayes_vectorizer.pkl', 'wb') as f:\n","    pickle.dump(pipeline_bow_nb.named_steps['bow'], f)"],"metadata":{"id":"fOr8dB2MyKPM","executionInfo":{"status":"ok","timestamp":1751853193191,"user_tz":180,"elapsed":3,"user":{"displayName":"Glauco Geremias","userId":"11920507635531894731"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["#***Modelo BERTimbau:***\n","\n","classifica textos em português usando o modelo BERTimbau da NeuralMind para transformar os textos em vetores numéricos (embeddings), e depois treina um classificador simples de regressão logística."],"metadata":{"id":"ruCcj_PJDjbF"}},{"cell_type":"markdown","source":["- Carrega o tokenizador e o modelo BERTimbau já treinado em português.\n"],"metadata":{"id":"MqfvFXOWEgIh"}},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n","model = AutoModel.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")"],"metadata":{"id":"R4KsVnBqhyMa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751853201590,"user_tz":180,"elapsed":8387,"user":{"displayName":"Glauco Geremias","userId":"11920507635531894731"}},"outputId":"e64f4cb1-8558-40fc-fe9b-2d86041ea83f"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["- Transforma um texto em um vetor numérico denso.\n","- Usa o [CLS] token (output.last_hidden_state[:, 0, :]) como representação do texto inteiro."],"metadata":{"id":"4_qIxm1HE3vU"}},{"cell_type":"code","source":["def gerar_embedding(texto):\n","    tokens = tokenizer(texto, return_tensors=\"pt\", truncation=True, padding=True, max_length=32)\n","    with torch.no_grad():\n","        output = model(**tokens)\n","    return output.last_hidden_state[:, 0, :].squeeze().numpy()"],"metadata":{"id":"c-_raZQzEvPS","executionInfo":{"status":"ok","timestamp":1751853201620,"user_tz":180,"elapsed":18,"user":{"displayName":"Glauco Geremias","userId":"11920507635531894731"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["- Seleciona um subconjunto de 1000 descrições e categorias aleatórias para não pesar demais na geração dos embeddings."],"metadata":{"id":"9SCW8WYgFZ8n"}},{"cell_type":"code","source":["X_small = dataset['descricao_processed'].sample(1000, random_state=42).reset_index(drop=True)\n","y_small = dataset[\"categoria\"].sample(1000, random_state=42).reset_index(drop=True)"],"metadata":{"id":"aOSj8HCnFYVH","executionInfo":{"status":"ok","timestamp":1751853201638,"user_tz":180,"elapsed":15,"user":{"displayName":"Glauco Geremias","userId":"11920507635531894731"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["- Para cada descrição, cria seu embedding BERT correspondente.\n","- Divide os embeddings e rótulos em treino e teste (70/30)."],"metadata":{"id":"3M4SoznJGG7B"}},{"cell_type":"code","source":["X_emb = np.array([gerar_embedding(t) for t in X_small])\n","X_train_e, X_test_e, y_train_e, y_test_e = train_test_split(X_emb, y_small, test_size=0.3, random_state=42)"],"metadata":{"id":"P-FKBx7RFwCy","executionInfo":{"status":"ok","timestamp":1751853339601,"user_tz":180,"elapsed":137960,"user":{"displayName":"Glauco Geremias","userId":"11920507635531894731"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["- Treina uma regressão logística sobre os embeddings."],"metadata":{"id":"UkFGT3Q1GQv4"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report, accuracy_score\n","from sklearn.linear_model import LogisticRegression\n","\n","modelo_logreg = LogisticRegression(max_iter=1000)\n","modelo_logreg.fit(X_train_e, y_train_e)\n","\n","y_pred_logreg_e = modelo_logreg.predict(X_test_e)\n","\n","print(\"BERTimbau + Regressão Logística\")\n","print(classification_report(y_test_e, y_pred_logreg_e))\n","print(\"\\nAcurácia do modelo (BERTimbau + Regressão Logística):\", accuracy_score(y_test_e, y_pred_logreg_e))"],"metadata":{"id":"l7KM7LnrGPvw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751853360083,"user_tz":180,"elapsed":20487,"user":{"displayName":"Glauco Geremias","userId":"11920507635531894731"}},"outputId":"0edcec76-3419-48c7-ee61-71b4e28303ce"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["BERTimbau + Regressão Logística\n","              precision    recall  f1-score   support\n","\n","         ABS       0.95      0.81      0.88        26\n","         AGU       0.83      1.00      0.91        10\n","         APL       0.60      1.00      0.75         3\n","         ASS       0.88      0.79      0.83        19\n","         BAR       0.67      0.74      0.71        39\n","         CAS       1.00      1.00      1.00         3\n","         CRD       1.00      0.91      0.95        11\n","         EDU       1.00      1.00      1.00         3\n","         IMP       1.00      0.25      0.40         4\n","         JUR       1.00      1.00      1.00        10\n","         LAZ       0.91      0.77      0.83        13\n","         LOJ       0.73      0.82      0.77        50\n","         MAN       1.00      0.33      0.50         3\n","         MER       0.68      0.76      0.72        45\n","         PED       0.86      0.86      0.86         7\n","         PET       1.00      1.00      1.00         4\n","         SAL       1.00      1.00      1.00         2\n","         SAU       1.00      0.83      0.91        29\n","         SEG       0.60      1.00      0.75         3\n","         TAR       1.00      0.80      0.89        10\n","         TRP       1.00      1.00      1.00         6\n","\n","    accuracy                           0.81       300\n","   macro avg       0.89      0.84      0.84       300\n","weighted avg       0.83      0.81      0.81       300\n","\n","\n","Acurácia do modelo (BERTimbau + Regressão Logística): 0.8133333333333334\n"]}]},{"cell_type":"code","metadata":{"id":"457041ed","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751853368936,"user_tz":180,"elapsed":8856,"user":{"displayName":"Glauco Geremias","userId":"11920507635531894731"}},"outputId":"891933ad-63d3-4109-a7e4-8719b1f60859"},"source":["import os\n","import pickle\n","from transformers import AutoModel, AutoTokenizer\n","\n","if not os.path.exists('models/bertimbau_model'):\n","    os.makedirs('models/bertimbau_model')\n","\n","if not os.path.exists('models/bertimbau_tokenizer'):\n","    os.makedirs('models/bertimbau_tokenizer')\n","\n","if not os.path.exists('models/bertimbau_logreg'):\n","    os.makedirs('models/bertimbau_logreg')\n","\n","bert_model_to_save = AutoModel.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n","bert_tokenizer_to_save = AutoTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n","\n","bert_model_to_save.save_pretrained('models/bertimbau_model')\n","\n","bert_tokenizer_to_save.save_pretrained('models/bertimbau_tokenizer')\n","\n","with open('models/bertimbau_logreg/modelo_logreg.pkl', 'wb') as f:\n","    pickle.dump(modelo_logreg, f)\n","\n","print(\"Modelo BERTimbau, tokenizer e modelo de regressão logística salvos na pasta 'models'!\")"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Modelo BERTimbau, tokenizer e modelo de regressão logística salvos na pasta 'models'!\n"]}]},{"cell_type":"markdown","source":["#***Modelo CNN***\n","\n","Este trecho de código está realizando a tokenização e o preenchimento (padding) de texto, para a preparação de dados de texto para redes neurais como CNNs.\n","\n","Preprocessamento:\n","- tokenizer = Tokenizer(): Inicializa um objeto Tokenizer do Keras.\n"," * num_words=1000: Limita o tokenizador a considerar apenas as 1000 palavras mais frequentes no conjunto de dados.\n"," * oov_token=\"<OOV>\": Define um token especial (<OOV> para Out-Of-Vocabulary, ou Fora do Vocabulário) para representar palavras que não estão entre as 1000 mais frequentes.\n","- tokenizer.fit_on_texts(): Treina o tokenizador nos dados de texto na coluna 'descricao_processed' do seu DataFrame. O tokenizador constrói um vocabulário com base nas palavras mais frequentes e atribui um número inteiro único a cada palavra.\n","- sequences = tokenizer.texts_to_sequences(): Converte as descrições de texto em sequências de números inteiros. Cada palavra em uma descrição é substituída pelo seu ID inteiro correspondente do vocabulário do tokenizador.\n","- padded = pad_sequences(sequences, maxlen=10, padding='post'): Garante que todas as sequências de números inteiros tenham o mesmo comprimento.\n"," * sequences: lista de entrada de sequências de números inteiros.\n"," * maxlen=10: Define o comprimento alvo para todas as sequências como 10.\n"," * padding='post': Adiciona preenchimento (zeros) no final das sequências com menos de 10 elementos. Se uma sequência for maior que 10, ela será truncada.\n","\n"],"metadata":{"id":"wmS7jJUkCOWc"}},{"cell_type":"code","source":["tokenizer = Tokenizer(num_words=1000, oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(dataset['descricao_processed'])\n","sequences = tokenizer.texts_to_sequences(dataset['descricao_processed'])\n","padded = pad_sequences(sequences, maxlen=10, padding='post')"],"metadata":{"id":"VI0ISeJ27gLB","executionInfo":{"status":"ok","timestamp":1751853368981,"user_tz":180,"elapsed":24,"user":{"displayName":"Glauco Geremias","userId":"11920507635531894731"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["Codificação das categorias:"],"metadata":{"id":"bkI26loAqYuP"}},{"cell_type":"code","source":["encoder = LabelEncoder()\n","labels = encoder.fit_transform(dataset['categoria'])\n","X_train_cnn, X_test_cnn, y_train_cnn, y_test_cnn = train_test_split(padded, labels, test_size=0.3)"],"metadata":{"id":"3fS9iywZqUtZ","executionInfo":{"status":"ok","timestamp":1751853368991,"user_tz":180,"elapsed":7,"user":{"displayName":"Glauco Geremias","userId":"11920507635531894731"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["Processamento:\n","\n","Cria um modelo sequencial — onde as camadas são adicionadas uma após a outra.\n","- Camada de embedding: transforma cada palavra (representada como um número inteiro) em um vetor denso.\n"," - input_dim=1000: o vocabulário tem até 1000 palavras únicas.\n"," - output_dim=50: cada palavra será representada por um vetor de 50 dimensões.\n","- Camada convolucional 1D: desliza um \"filtro\" sobre a sequência de embeddings, detectando padrões locais (por exemplo: \"atraso pagamento\" ou \"conta vencida\").\n"," - filters=64: número de filtros aplicados.\n"," - kernel_size=3: o tamanho do “n-grama” textual capturado por cada filtro.\n"," - activation='softmax': introduz não linearidade.\n","- Camada de pooling: pega o valor máximo de cada filtro ao longo da sequência, reduzindo a dimensionalidade e mantendo as características mais relevantes.\n","- Camada totalmente conectada (hidden layer), com 64 neurônios e função de ativação softmax.\n","- Camada de saída, com uma unidade para cada classe única presente em labels.\n","- activation='softmax': converte os outputs em probabilidades somando 1 — ideal para classificação multiclasse."],"metadata":{"id":"Fuked1ic4bvJ"}},{"cell_type":"code","source":["model = Sequential([\n","    Embedding(input_dim=1000, output_dim=50),\n","    Conv1D(filters=64, kernel_size=3, activation='softmax'),\n","    GlobalMaxPooling1D(),\n","    Dense(64, activation='relu'),\n","    Dense(len(np.unique(labels)), activation='softmax')\n","])"],"metadata":{"id":"RPQFCwCCtEtw","executionInfo":{"status":"ok","timestamp":1751853369007,"user_tz":180,"elapsed":9,"user":{"displayName":"Glauco Geremias","userId":"11920507635531894731"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["Prepara e treina a rede neural com Keras para o problema de classificação multiclasse"],"metadata":{"id":"LLPs7Sga7Twd"}},{"cell_type":"code","source":["from tensorflow.keras.callbacks import EarlyStopping\n","import numpy as np\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), callbacks=[early_stop], verbose=1)\n","\n","print(\"CNN\")\n","# Get predicted classes\n","y_pred_cnn = np.argmax(model.predict(X_test), axis=-1)\n","print(classification_report(y_test, y_pred_cnn))\n","print(\"\\nAcurácia do modelo (CNN):\", accuracy_score(y_test, y_pred_cnn))"],"metadata":{"id":"_nRBPpZ37LF1","colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"status":"error","timestamp":1751853369388,"user_tz":180,"elapsed":379,"user":{"displayName":"Glauco Geremias","userId":"11920507635531894731"}},"outputId":"8f0bfe2d-255c-4444-d43c-d3dbd8b05dbd"},"execution_count":25,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Invalid dtype: object","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-25-256898865.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CNN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optree/ops.py\u001b[0m in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0mleaves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreespec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnone_is_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0mflat_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleaves\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtreespec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_up_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrests\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtreespec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mflat_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Invalid dtype: object"]}]},{"cell_type":"code","metadata":{"id":"f13c4865","executionInfo":{"status":"aborted","timestamp":1751853369564,"user_tz":180,"elapsed":2,"user":{"displayName":"Glauco Geremias","userId":"11920507635531894731"}}},"source":["import pickle\n","import os\n","\n","if not os.path.exists('models'):\n","    os.makedirs('models')\n","\n","model.save('models/cnn_model.h5')\n","\n","with open('models/cnn_tokenizer.pkl', 'wb') as f:\n","    pickle.dump(tokenizer, f)\n","\n","with open('models/cnn_label_encoder.pkl', 'wb') as f:\n","    pickle.dump(encoder, f)\n","\n","\n","print(\"Modelos, vetorizadores, tokenizer e encoder salvos com sucesso!\")"],"execution_count":null,"outputs":[]}]}